{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7047707-008f-451f-bede-c88593a50a27",
   "metadata": {},
   "source": [
    "## Test with small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf455b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = 'data/checkpoints/0906_214036/model_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc2b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "import model.loss as module_loss\n",
    "import model.model as module_arch\n",
    "import model.metric as module_metric\n",
    "from parse_config import ConfigParser\n",
    "import data_loader.data_loaders as module_data\n",
    "from utils.span2json import span2json\n",
    "from utils.conll2span import conll2span\n",
    "from utils.correcting_labels import fix_labels\n",
    "\n",
    "PAD = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0baa04c-5085-49d1-bf95-61907c720449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.correcting_labels import fix_labels, remove_incorrect_tag\n",
    "def get_dict_prediction(tokens, preds, attention_mask, ids2tag):\n",
    "    temp_preds=[]\n",
    "    for index in range(len(preds)):    \n",
    "        if attention_mask[index]==1:\n",
    "            Ptag = ids2tag.get(preds[index].item())\n",
    "            temp_preds.append(Ptag)\n",
    "            \n",
    "    temp_preds = remove_incorrect_tag(temp_preds, \"BIOES\")\n",
    "    temp_preds = fix_labels(temp_preds, \"BIOES\")    \n",
    "    temp_preds = conll2span(temp_preds)\n",
    "    temp_preds = span2json(tokens, temp_preds)   \n",
    "    return temp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7614cbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNEModel(\n",
      "  (lm): CamembertModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(25005, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (3): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (4): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (5): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (6): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (7): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 107809800\n",
      "Loading checkpoint: data/checkpoints/0906_214036/model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)')\n",
    "args.add_argument('-r', '--resume', default=f\"{resume}\", type=str, help='path to latest checkpoint (default: None)')\n",
    "args.add_argument('-d', '--device', default=None, type=str, help='indices of GPUs to enable (default: all)')\n",
    "args.add_argument('-f', '--file', default=None, type=str, help='Error')\n",
    "\n",
    "config = ConfigParser.from_args(args)\n",
    "logger = config.get_logger('test')\n",
    "\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "test_data_loader = data_loader.get_test()\n",
    "\n",
    "# build model architecturea\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "criterion = getattr(module_loss, config['loss'])\n",
    "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
    "checkpoint = torch.load(config.resume)\n",
    "state_dict = checkpoint['state_dict']\n",
    "if config['n_gpu'] > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(state_dict)\n",
    "layers_train = config._config['trainer']['layers_train']\n",
    "\n",
    "# prepare model for testing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "total_metrics = torch.zeros(len(metric_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce78f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/weerayut/anaconda3/envs/workspace/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weerayut/anaconda3/envs/workspace/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "3it [00:24,  8.26s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, instance in tqdm(enumerate(test_data_loader)):\n",
    "        input_ids = torch.tensor(instance['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(instance['attention_mask']).to(device)\n",
    "        batch_size = input_ids.shape[0]\n",
    "        output = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = 0\n",
    "        nested_lm_conll_ids = {l:None for l in range(len(layers_train))}\n",
    "        for index, layer in enumerate(layers_train):\n",
    "            temp_nested_lm_conll_ids = torch.tensor(instance['nested_lm_conll_ids'][layer])\n",
    "            temp_nested_lm_conll_ids = temp_nested_lm_conll_ids.to(device)\n",
    "            nested_lm_conll_ids[index]=temp_nested_lm_conll_ids\n",
    "            loss+=criterion(output[index], temp_nested_lm_conll_ids)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        predictions = {x:[] for x in range(batch_size)}\n",
    "        lm_entities = {x:[] for x in range(batch_size)}\n",
    "        \n",
    "        for sent_ids in range(batch_size):\n",
    "            for layer in range(len(output)):\n",
    "                predictions[sent_ids].append(output[layer][sent_ids].argmax(axis=0))\n",
    "                lm_entities[sent_ids].append(nested_lm_conll_ids[layer][sent_ids])\n",
    "        for sent_ids in range(batch_size):\n",
    "            tokens = instance['lm_tokens'][sent_ids]\n",
    "            tokens = [w for w in tokens if w!=PAD]\n",
    "            preds = []\n",
    "            for index in range(len(layers_train)):\n",
    "                preds+=get_dict_prediction(\n",
    "                        tokens, \n",
    "                        predictions[sent_ids][index], \n",
    "                        attention_mask[sent_ids], \n",
    "                        data_loader.ids2tag)\n",
    "            entities_labels = []\n",
    "            for index in range(len(layers_train)):\n",
    "                entities_labels+=get_dict_prediction(\n",
    "                    tokens, \n",
    "                    lm_entities[sent_ids][index], \n",
    "                    attention_mask[sent_ids], \n",
    "                    data_loader.ids2tag)\n",
    "            results.append({\n",
    "                'sentence_id': instance['sentence_id'][sent_ids],\n",
    "                'tokens': tokens,\n",
    "                'entities': entities_labels,\n",
    "                'predictions':preds})\n",
    "            for i, metric in enumerate(metric_fns):\n",
    "                total_metrics[i] += metric( \n",
    "                        output, nested_lm_conll_ids, attention_mask, \n",
    "                        data_loader.boundary_type, info=False, ids2tag=data_loader.ids2tag\n",
    "            ) * batch_size     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03f91d-57d1-4389-ac13-eb6b6be2fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "output = []\n",
    "n_limit = 1\n",
    "for ids, item in enumerate(results[:n_limit]):\n",
    "    print('\\n',\"\".join(item[\"tokens\"]),'\\n')\n",
    "    sid = item['sentence_id']\n",
    "    entities=item['entities']\n",
    "    predictions=item['predictions']\n",
    "\n",
    "    for pred in predictions:\n",
    "        tag = \"/\" if pred in entities else \"X\"\n",
    "        out = [f\"SID:{sid}\", tag, ''.join(pred['text']), pred['entity_type']]\n",
    "        print(out)\n",
    "\n",
    "#     for en in entities:\n",
    "#         tag = \"N\" if en not in predictions else \"-\"\n",
    "#         out = [f\"SID:{sid}\", tag, ''.join(en['text']), en['entity_type']]\n",
    "#         print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can input both BIESO and BIO\n",
    "from model.eval import ClassEvaluator\n",
    "results_eval, conll_results = ClassEvaluator()(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fa956-a64d-4e63-a329-4763298822ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:workspace] *",
   "language": "python",
   "name": "conda-env-workspace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

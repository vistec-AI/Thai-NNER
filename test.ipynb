{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf455b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = 'data/checkpoints/0906_214036/model_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc2b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "import model.loss as module_loss\n",
    "import model.model as module_arch\n",
    "import model.metric as module_metric\n",
    "from parse_config import ConfigParser\n",
    "import data_loader.data_loaders as module_data\n",
    "from utils.span2json import span2json\n",
    "from utils.conll2span import conll2span\n",
    "from utils.correcting_labels import fix_labels\n",
    "\n",
    "PAD = '<pad>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0baa04c-5085-49d1-bf95-61907c720449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.correcting_labels import fix_labels, remove_incorrect_tag\n",
    "def get_dict_prediction(tokens, preds, attention_mask, ids2tag):\n",
    "    temp_preds=[]\n",
    "    for index in range(len(preds)):    \n",
    "        if attention_mask[index]==1:\n",
    "            Ptag = ids2tag.get(preds[index].item())\n",
    "            temp_preds.append(Ptag)\n",
    "            \n",
    "    temp_preds = remove_incorrect_tag(temp_preds, \"BIOES\")\n",
    "    temp_preds = fix_labels(temp_preds, \"BIOES\")    \n",
    "    temp_preds = conll2span(temp_preds)\n",
    "    temp_preds = span2json(tokens, temp_preds)   \n",
    "    return temp_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7614cbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNEModel(\n",
      "  (lm): CamembertModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(25005, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (3): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (4): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (5): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (6): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "    (7): Decoder(\n",
      "      (fc1): Linear(in_features=768, out_features=417, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 107809800\n",
      "Loading checkpoint: data/checkpoints/0906_214036/model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)')\n",
    "args.add_argument('-r', '--resume', default=f\"{resume}\", type=str, help='path to latest checkpoint (default: None)')\n",
    "args.add_argument('-d', '--device', default=None, type=str, help='indices of GPUs to enable (default: all)')\n",
    "args.add_argument('-f', '--file', default=None, type=str, help='Error')\n",
    "\n",
    "config = ConfigParser.from_args(args)\n",
    "logger = config.get_logger('test')\n",
    "\n",
    "data_loader = config.init_obj('data_loader', module_data)\n",
    "test_data_loader = data_loader.get_test()\n",
    "\n",
    "# build model architecturea\n",
    "model = config.init_obj('arch', module_arch)\n",
    "logger.info(model)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "criterion = getattr(module_loss, config['loss'])\n",
    "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
    "checkpoint = torch.load(config.resume)\n",
    "state_dict = checkpoint['state_dict']\n",
    "if config['n_gpu'] > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model.load_state_dict(state_dict)\n",
    "layers_train = config._config['trainer']['layers_train']\n",
    "\n",
    "# prepare model for testing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "total_metrics = torch.zeros(len(metric_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce78f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/weerayut/anaconda3/envs/workspace/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/weerayut/anaconda3/envs/workspace/lib/python3.6/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "5it [00:35,  7.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, instance in tqdm(enumerate(test_data_loader)):\n",
    "        input_ids = torch.tensor(instance['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(instance['attention_mask']).to(device)\n",
    "        batch_size = input_ids.shape[0]\n",
    "        output = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = 0\n",
    "        nested_lm_conll_ids = {l:None for l in range(len(layers_train))}\n",
    "        for index, layer in enumerate(layers_train):\n",
    "            temp_nested_lm_conll_ids = torch.tensor(instance['nested_lm_conll_ids'][layer])\n",
    "            temp_nested_lm_conll_ids = temp_nested_lm_conll_ids.to(device)\n",
    "            nested_lm_conll_ids[index]=temp_nested_lm_conll_ids\n",
    "            loss+=criterion(output[index], temp_nested_lm_conll_ids)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        predictions = {x:[] for x in range(batch_size)}\n",
    "        lm_entities = {x:[] for x in range(batch_size)}\n",
    "        \n",
    "        for sent_ids in range(batch_size):\n",
    "            for layer in range(len(output)):\n",
    "                predictions[sent_ids].append(output[layer][sent_ids].argmax(axis=0))\n",
    "                lm_entities[sent_ids].append(nested_lm_conll_ids[layer][sent_ids])\n",
    "        for sent_ids in range(batch_size):\n",
    "            tokens = instance['lm_tokens'][sent_ids]\n",
    "            tokens = [w for w in tokens if w!=PAD]\n",
    "            preds = []\n",
    "            for index in range(len(layers_train)):\n",
    "                preds+=get_dict_prediction(\n",
    "                        tokens, \n",
    "                        predictions[sent_ids][index], \n",
    "                        attention_mask[sent_ids], \n",
    "                        data_loader.ids2tag)\n",
    "            entities_labels = []\n",
    "            for index in range(len(layers_train)):\n",
    "                entities_labels+=get_dict_prediction(\n",
    "                    tokens, \n",
    "                    lm_entities[sent_ids][index], \n",
    "                    attention_mask[sent_ids], \n",
    "                    data_loader.ids2tag)\n",
    "            results.append({\n",
    "                'sentence_id': instance['sentence_id'][sent_ids],\n",
    "                'tokens': tokens,\n",
    "                'entities': entities_labels,\n",
    "                'predictions':preds})\n",
    "            for i, metric in enumerate(metric_fns):\n",
    "                total_metrics[i] += metric( \n",
    "                        output, nested_lm_conll_ids, attention_mask, \n",
    "                        data_loader.boundary_type, info=False, ids2tag=data_loader.ids2tag\n",
    "            ) * batch_size     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec1ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate F1-score based on.\n",
      "labels_true: 1138\n",
      "num_labels: 1670\n",
      "predictions_true: 1154\n",
      "num_predictions: 1297\n",
      "\n",
      "<<< Results Evaluations >>>\n",
      "\n",
      "-------------  ---------  -------  -------  ----------------  ---------------  ----------\n",
      "group/n.class  precision  recall   f1       predictions_true  num_predictions  num_labels\n",
      "group 0: 20    90.4675    80.0823  84.9587  987               1091             1215\n",
      "group 1: 19    83.4356    53.1496  64.9348  136               163              254\n",
      "group 2: 65    72.093     14.9254  24.7308  31                43               201\n",
      "-------------  ---------  -------  -------  ----------------  ---------------  ----------\n",
      "----------------  ---------  -------  --------  ----------  ---------  ----------\n",
      "tag               precision  recall   f1-score  preds_true  num_preds  num_labels\n",
      "total             88.9746    68.1437  77.1783   1154        1297       1670\n",
      "cardinal          88.8199    80.117   84.2442   143         161        171\n",
      "country           94.6237    86.8687  90.5805   88          93         99\n",
      "person            92.5926    86.2069  89.2857   75          81         87\n",
      "unit              96.0       84.7059  90.0      72          75         85\n",
      "goverment         84.4828    62.8205  72.0588   49          58         78\n",
      "role              87.0968    36.4865  51.4286   27          31         74\n",
      "firstname         79.7297    81.9444  80.8219   59          74         72\n",
      "month             100.0      100.0    100.0     58          58         58\n",
      "province          98.2759    93.1034  95.6198   57          58         58\n",
      "last              92.3077    84.2105  88.0734   48          52         57\n",
      "date              96.0       90.566   93.2039   48          50         53\n",
      "title             91.0714    98.0769  94.4444   51          56         52\n",
      "day               89.2857    94.2308  91.6916   50          56         52\n",
      "quantity          94.7368    78.2609  85.7143   36          38         46\n",
      "year              95.7447    100.0    97.8261   45          47         44\n",
      "district          97.0588    84.2105  90.1793   33          34         38\n",
      "loc_others        69.2308    29.0323  40.9091   9           13         31\n",
      "orgcorp           91.3043    70.0     79.2453   21          23         30\n",
      "facility_other    38.4615    16.6667  23.2558   5           13         30\n",
      "media             89.2857    86.2069  87.7193   25          28         29\n",
      "org_other         45.4545    40.0     42.5532   10          22         25\n",
      "org_edu           92.3077    55.0     68.9295   12          13         20\n",
      "norp_political    60.0       15.0     24.0      3           5          20\n",
      "disease           100.0      57.8947  73.3333   11          11         19\n",
      "product_food      0          0        0         0           1          18\n",
      "time              80.0       94.1176  86.4865   16          20         17\n",
      "duration          100.0      70.5882  82.7586   12          12         17\n",
      "rel               88.8889    53.3333  66.6667   8           9          15\n",
      "city              76.4706    100.0    86.6667   13          17         13\n",
      "nationality       100.0      15.3846  26.6667   2           2          13\n",
      "event_others      50.0       7.6923   13.3333   1           2          13\n",
      "nickname          100.0      8.3333   15.3846   1           1          12\n",
      "mult              88.8889    88.8889  88.8889   8           9          9\n",
      "continent         100.0      33.3333  50.0      4           4          9\n",
      "state             100.0      22.2222  36.3636   2           2          9\n",
      "norp_others       0          0        0         0           0          9\n",
      "money             100.0      100.0    100.0     8           8          8\n",
      "sub_district      72.7273    100.0    84.2105   8           11         8\n",
      "roadname          100.0      57.1429  72.7273   4           4          7\n",
      "vehicle           0          0        0         0           0          7\n",
      "org_political     66.6667    66.6667  66.6667   4           6          6\n",
      "tv_show           100.0      50.0     66.6667   3           3          6\n",
      "weapon            0          0        0         0           0          6\n",
      "song              100.0      60.0     75.0      3           3          5\n",
      "restaurant        100.0      40.0     57.1429   2           2          5\n",
      "hotel             50.0       20.0     28.5714   1           2          5\n",
      "animal_species    0          0        0         0           0          5\n",
      "fund              0          0        0         0           0          5\n",
      "bridge            100.0      50.0     66.6667   2           2          4\n",
      "island            100.0      50.0     66.6667   2           2          4\n",
      "space             0          0        0         0           0          4\n",
      "natural_disaster  0          0        0         0           3          4\n",
      "museum            0          0        0         0           0          4\n",
      "stock_exchange    0          0        0         0           0          4\n",
      "book              0          0        0         0           2          4\n",
      "sports_team       0          0        0         0           0          4\n",
      "station           0          0        0         0           0          4\n",
      "jargon            100.0      100.0    100.0     3           3          3\n",
      "percent           100.0      66.6667  80.0      2           2          3\n",
      "address           0          0        0         0           1          3\n",
      "product_drug      0          0        0         0           0          3\n",
      "distance          0          0        0         0           1          3\n",
      "film              0          0        0         0           0          3\n",
      "airport           100.0      100.0    100.0     2           2          2\n",
      "law               100.0      100.0    100.0     2           2          2\n",
      "language          100.0      100.0    100.0     2           2          2\n",
      "river             100.0      50.0     66.6667   1           1          2\n",
      "building          100.0      50.0     66.6667   1           1          2\n",
      "psudoname         100.0      50.0     66.6667   1           1          2\n",
      "longtitude        0          0        0         0           0          2\n",
      "band              0          0        0         0           0          2\n",
      "season            0          0        0         0           0          2\n",
      "religion          0          0        0         0           0          2\n",
      "sciname           0          0        0         0           2          2\n",
      "award             0          0        0         0           0          2\n",
      "temperature       0          0        0         0           0          2\n",
      "food_ingredient   0          0        0         0           0          2\n",
      "periodic          0          0        0         0           1          2\n",
      "war               0          0        0         0           0          2\n",
      "mountian          0          0        0         0           0          2\n",
      "org_religious     0          0        0         0           0          2\n",
      "latitude          0          0        0         0           0          2\n",
      "namemod           0          0        0         0           0          2\n",
      "hospital          100.0      100.0    100.0     1           1          1\n",
      "army              0          0        0         0           0          1\n",
      "fold              0          0        0         0           0          1\n",
      "stadium           0          0        0         0           0          1\n",
      "god               0          0        0         0           0          1\n",
      "concert           0          0        0         0           0          1\n",
      "soi               0          0        0         0           0          1\n",
      "middle            0          0        0         0           0          1\n",
      "energy            0          0        0         0           0          1\n",
      "nicknametitle     0          0        0         0           0          1\n",
      "postcode          0          0        0         0           0          1\n",
      "ocean             0          0        0         0           0          1\n",
      "woa               0          0        0         0           0          1\n",
      "weight            0          0        0         0           0          1\n",
      "speed             0          0        0         0           0          1\n",
      "electronics       0          0        0         0           0          1\n",
      "index             0          0        0         0           0          1\n",
      "sports_event      0          0        0         0           0          1\n",
      "animate           0          0        0         0           0          1\n",
      "port              0          0        0         0           0          1\n",
      "game              0          0        0         0           0          1\n",
      "----------------  ---------  -------  --------  ----------  ---------  ----------\n"
     ]
    }
   ],
   "source": [
    "## Can input both BIESO and BIO\n",
    "from model.eval import ClassEvaluator\n",
    "results_eval, conll_results = ClassEvaluator()(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e04205-ceb5-4535-a26d-89b8ad7cb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f422d7b-0ec9-4bd1-aefb-47d1286a4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "        print(tabulate(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31ec5795-e087-4a91-a025-5ea4e73d6200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence_id', 'tokens', 'entities', 'predictions'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a03f91d-57d1-4389-ac13-eb6b6be2fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <s>ความคืบหน้าหลังศาลปกครองกลางมีคําสั่งไม่รับคําฟ้องและไม่คุ้มครองชั่วคราวในคดีที่ผู้ตรวจการแผ่นดินยื่นฟ้องต่อศาลปกครองว่า_สํานักงานคณะกรรมการกิจการกระจายเสียง_กิจการโทรทัศน์และกิจการโทรคมนาคมแห่งชาติ_กสทช._จัดการประมูลคลื่นความถี่_ย่าน_2.1<unk>z_พร้อมทั้งออกประกาศ_เรื่อง_หลักเกณฑ์และวิธีการอนุญาตให้ใช้คลื่นความถี่ดังกล่าวโดยไม่ชอบด้วยกฎหมาย_ด้วยเหตุผลว่า_ผู้ตรวจการแผ่นดิน_ไม่มีสิทธิและหน้าที่_เสมือนหนึ่งผู้ฟ้องคดี_เมื่อวันที่_3_ธ.ค.55_ล่าสุด_3_ม.ค.56_ผู้ตรวจการแผ่นดินได้ยื่นอุทธรณ์คําสั่งไม่รับคําฟ้องของศาลปกครองกลางแล้ว</s> \n",
      "\n",
      "['SID:0', 'X', 'ศาลปกครองกลาง', 'goverment']\n",
      "['SID:0', '/', 'ศาลปกครอง', 'goverment']\n",
      "['SID:0', '/', 'สํานักงานคณะกรรมการกิจการกระจายเสียง_กิจการโทรทัศน์และกิจการโทรคมนาคมแห่งชาติ', 'goverment']\n",
      "['SID:0', '/', 'กสทช.', 'goverment']\n",
      "['SID:0', '/', 'วันที่_3_ธ.ค.55', 'date']\n",
      "['SID:0', '/', '3_ม.ค.56', 'date']\n",
      "['SID:0', '/', 'ศาลปกครองกลาง', 'goverment']\n",
      "['SID:0', '/', 'วันที่_3', 'day']\n",
      "['SID:0', '/', 'ธ.ค.', 'month']\n",
      "['SID:0', '/', '55', 'year']\n",
      "['SID:0', '/', '3', 'day']\n",
      "['SID:0', '/', 'ม.ค.', 'month']\n",
      "['SID:0', '/', '56', 'year']\n",
      "['SID:0', '/', '3', 'cardinal']\n",
      "['SID:0', 'N', 'ศาลปกครองกลาง', 'org_other']\n",
      "['SID:0', 'N', 'ผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:0', '-', 'ศาลปกครอง', 'goverment']\n",
      "['SID:0', 'N', 'สํานักงานคณะกรรมการกิจการกระจายเสียง_กิจการโทรทัศน์และกิจการโทรคมนาคมแห่งชาติ_กสทช.', 'goverment']\n",
      "['SID:0', 'N', '2.1<unk>z', 'quantity']\n",
      "['SID:0', 'N', 'ผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:0', '-', 'วันที่_3_ธ.ค.55', 'date']\n",
      "['SID:0', '-', '3_ม.ค.56', 'date']\n",
      "['SID:0', 'N', 'ผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:0', '-', 'ศาลปกครองกลาง', 'goverment']\n",
      "['SID:0', '-', 'สํานักงานคณะกรรมการกิจการกระจายเสียง_กิจการโทรทัศน์และกิจการโทรคมนาคมแห่งชาติ', 'goverment']\n",
      "['SID:0', '-', 'กสทช.', 'goverment']\n",
      "['SID:0', 'N', '2.1', 'cardinal']\n",
      "['SID:0', 'N', '<unk>z', 'unit']\n",
      "['SID:0', '-', 'วันที่_3', 'day']\n",
      "['SID:0', '-', 'ธ.ค.', 'month']\n",
      "['SID:0', '-', '55', 'year']\n",
      "['SID:0', '-', '3', 'day']\n",
      "['SID:0', '-', 'ม.ค.', 'month']\n",
      "['SID:0', '-', '56', 'year']\n",
      "['SID:0', 'N', 'คณะกรรมการกิจการกระจายเสียง_กิจการโทรทัศน์และกิจการโทรคมนาคมแห่งชาติ', 'role']\n",
      "['SID:0', '-', '3', 'cardinal']\n",
      "\n",
      " <s>โดยเว็บไซต์เนชั่นทันข่าว_[1]รายงานว่า_รักษเกชา_แฉ่ฉาย_โฆษกสํานักงานผู้ตรวจการแผ่นดิน_แถลงว่า_ผู้ตรวจการแผ่นดินได้ยื่นอุทธรณ์คําสั่งไม่รับคําฟ้องของศาลปกครองกลางกรณีขอให้เพิกถอนการจัดประมูลคลื่นความถี่_3<unk>_ต่อศาลปกครองสูงสุดแล้ว_โดยยื่นทางไปรษณีย์ไปเมื่อวันที่_28_ธ.ค._2555_และตรวจสอบแล้วว่าคําร้องอุทธรณ์ส่งถึงสํานักงานศาลปกครองแล้วเมื่อช่วงบ่ายของวันที่_2_ม.ค._2556_ที่ผ่านมา_ทั้งนี้_การยื่นอุทธรณ์ดังกล่าวเป็นการยื่นในประเด็นเดิมโดยผู้ตรวจฯ</s> \n",
      "\n",
      "['SID:1', '/', 'เนชั่นทันข่าว', 'media']\n",
      "['SID:1', '/', '1', 'cardinal']\n",
      "['SID:1', '/', 'โฆษกสํานักงานผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:1', '/', 'วันที่_28_ธ.ค._2555', 'date']\n",
      "['SID:1', '/', 'วันที่_2_ม.ค._2556', 'date']\n",
      "['SID:1', '/', 'เนชั่น', 'media']\n",
      "['SID:1', '/', 'สํานักงานผู้ตรวจการแผ่นดิน', 'goverment']\n",
      "['SID:1', '/', 'วันที่_28', 'day']\n",
      "['SID:1', '/', 'ธ.ค.', 'month']\n",
      "['SID:1', '/', '2555', 'year']\n",
      "['SID:1', '/', 'วันที่_2', 'day']\n",
      "['SID:1', '/', 'ม.ค.', 'month']\n",
      "['SID:1', '/', '2556', 'year']\n",
      "['SID:1', 'X', '28', 'cardinal']\n",
      "['SID:1', '/', '2', 'cardinal']\n",
      "['SID:1', '-', 'เนชั่นทันข่าว', 'media']\n",
      "['SID:1', '-', '1', 'cardinal']\n",
      "['SID:1', 'N', 'รักษเกชา_แฉ่ฉาย', 'person']\n",
      "['SID:1', '-', 'โฆษกสํานักงานผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:1', 'N', 'ผู้ตรวจการแผ่นดิน', 'role']\n",
      "['SID:1', 'N', 'ศาลปกครองกลาง', 'goverment']\n",
      "['SID:1', 'N', '3<unk>', 'quantity']\n",
      "['SID:1', 'N', 'ศาลปกครองสูงสุด', 'goverment']\n",
      "['SID:1', '-', 'วันที่_28_ธ.ค._2555', 'date']\n",
      "['SID:1', 'N', 'สํานักงานศาลปกครอง', 'goverment']\n",
      "['SID:1', '-', 'วันที่_2_ม.ค._2556', 'date']\n",
      "['SID:1', '-', 'เนชั่น', 'media']\n",
      "['SID:1', 'N', 'รักษเกชา', 'firstname']\n",
      "['SID:1', 'N', 'แฉ่ฉาย', 'last']\n",
      "['SID:1', '-', 'สํานักงานผู้ตรวจการแผ่นดิน', 'goverment']\n",
      "['SID:1', 'N', '3', 'cardinal']\n",
      "['SID:1', '-', 'วันที่_28', 'day']\n",
      "['SID:1', '-', 'ธ.ค.', 'month']\n",
      "['SID:1', '-', '2555', 'year']\n",
      "['SID:1', 'N', 'ศาลปกครอง', 'facility_other']\n",
      "['SID:1', '-', 'วันที่_2', 'day']\n",
      "['SID:1', '-', 'ม.ค.', 'month']\n",
      "['SID:1', '-', '2556', 'year']\n",
      "['SID:1', '-', '2', 'cardinal']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "output = []\n",
    "n_limit = 2\n",
    "for ids, item in enumerate(results[:n_limit]):\n",
    "    print('\\n',\"\".join(item[\"tokens\"]),'\\n')\n",
    "    sid = item['sentence_id']\n",
    "    entities=item['entities']\n",
    "    predictions=item['predictions']\n",
    "\n",
    "    for pred in predictions:\n",
    "        tag = \"/\" if pred in entities else \"X\"\n",
    "        out = [f\"SID:{sid}\", tag, ''.join(pred['text']), pred['entity_type']]\n",
    "        print(out)\n",
    "    \n",
    "    for en in entities:\n",
    "        tag = \"N\" if en not in predictions else \"-\"\n",
    "        out = [f\"SID:{sid}\", tag, ''.join(en['text']), en['entity_type']]\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fa956-a64d-4e63-a329-4763298822ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:workspace] *",
   "language": "python",
   "name": "conda-env-workspace-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
